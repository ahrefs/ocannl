<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Tensor (neural_nets_lib.Ocannl_tensor.Tensor)</title><meta charset="utf-8"/><link rel="stylesheet" href="../../../odoc.support/odoc.css"/><meta name="generator" content="odoc 3.1.0"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../../odoc.support/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body class="odoc"><nav class="odoc-nav"><a href="../index.html">Up</a> â€“ <a href="../../../index.html">Index</a> &#x00BB; <a href="../../index.html">neural_nets_lib</a> &#x00BB; <a href="../index.html">Ocannl_tensor</a> &#x00BB; Tensor</nav><header class="odoc-preamble"><h1>Module <code><span>Ocannl_tensor.Tensor</span></code></h1></header><div class="odoc-tocs"><nav class="odoc-toc odoc-local-toc"><ul><li><a href="#construction-of-runtime-compiled-code-supporting-backpropagation.">Construction of runtime-compiled code supporting backpropagation.</a><ul><li><a href="#printing.">Printing.</a></li></ul></li></ul></nav></div><div class="odoc-content"><h2 id="construction-of-runtime-compiled-code-supporting-backpropagation."><a href="#construction-of-runtime-compiled-code-supporting-backpropagation." class="anchor"></a>Construction of runtime-compiled code supporting backpropagation.</h2><div class="odoc-spec"><div class="spec type anchored" id="type-ndarray"><a href="#type-ndarray" class="anchor"></a><code><span><span class="keyword">type</span> ndarray</span><span> = <a href="../../../arrayjit/Ir/Ndarray/index.html#type-t">Ir.Ndarray.t</a></span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-tn"><a href="#type-tn" class="anchor"></a><code><span><span class="keyword">type</span> tn</span><span> = <a href="../../../arrayjit/Ir/Tnode/index.html#type-t">Ir.Tnode.t</a></span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-tn_set"><a href="#type-tn_set" class="anchor"></a><code><span><span class="keyword">type</span> tn_set</span><span> = <span class="xref-unresolved">Base</span>.Set.M(<span class="xref-unresolved">Ir</span>.Tnode).t</span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-asgns"><a href="#type-asgns" class="anchor"></a><code><span><span class="keyword">type</span> asgns</span><span> = <a href="../../../arrayjit/Ir/Assignments/index.html#type-t">Ir.Assignments.t</a></span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-comp"><a href="#type-comp" class="anchor"></a><code><span><span class="keyword">type</span> comp</span><span> = <a href="../../../arrayjit/Ir/Assignments/index.html#type-comp">Ir.Assignments.comp</a></span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-fetch_op"><a href="#type-fetch_op" class="anchor"></a><code><span><span class="keyword">type</span> fetch_op</span><span> = <a href="../../../arrayjit/Ir/Assignments/index.html#type-fetch_op">Ir.Assignments.fetch_op</a></span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-projections"><a href="#type-projections" class="anchor"></a><code><span><span class="keyword">type</span> projections</span><span> = </span><span>{</span></code><ol><li id="type-projections.projections_debug" class="def record field anchored"><a href="#type-projections.projections_debug" class="anchor"></a><code><span>projections_debug : <span class="xref-unresolved">Base</span>.string;</span></code></li><li id="type-projections.projections" class="def record field anchored"><a href="#type-projections.projections" class="anchor"></a><code><span>projections : <span><a href="../../../arrayjit/Ir/Indexing/index.html#type-projections">Ir.Indexing.projections</a> <span class="xref-unresolved">Base</span>.Lazy.t</span>;</span></code></li></ol><code><span>}</span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-diff"><a href="#type-diff" class="anchor"></a><code><span><span class="keyword">type</span> diff</span><span> = </span><span>{</span></code><ol><li id="type-diff.grad" class="def record field anchored"><a href="#type-diff.grad" class="anchor"></a><code><span>grad : <a href="#type-tn">tn</a>;</span></code></li><li id="type-diff.zero_grads" class="def record field anchored"><a href="#type-diff.zero_grads" class="anchor"></a><code><span>zero_grads : <a href="#type-asgns">asgns</a>;</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>Prepares for backpropagation. Beware of the &quot;missing zero_grads&quot; bug.</p><span class="comment-delim">*)</span></div></li><li id="type-diff.backprop" class="def record field anchored"><a href="#type-diff.backprop" class="anchor"></a><code><span>backprop : <a href="#type-comp">comp</a>;</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>Backpropagates for the tensor and its descendants; which typically means adding partial gradients to the gradient tensor of the subtensors, then for sub-subtensors etc.</p><span class="comment-delim">*)</span></div></li></ol><code><span>}</span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-t"><a href="#type-t" class="anchor"></a><code><span><span class="keyword">type</span> t</span><span> = </span><span>{</span></code><ol><li id="type-t.params" class="def record field anchored"><a href="#type-t.params" class="anchor"></a><code><span>params : <span><span>(<a href="#type-t">t</a>, <a href="#type-comparator_witness">comparator_witness</a>)</span> <span class="xref-unresolved">Base</span>.Set.t</span>;</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>Parameters <code>t.params</code> are the descendants of <code>t</code> whose <a href="#type-t.diff"><code>diff</code></a> is not <code>None</code> and whose <a href="#type-t.forward"><code>forward</code></a> code is not included in <code>t.forward</code> as it is meant for initialization.</p><span class="comment-delim">*)</span></div></li><li id="type-t.forward" class="def record field anchored"><a href="#type-t.forward" class="anchor"></a><code><span>forward : <a href="#type-comp">comp</a>;</span></code></li><li id="type-t.diff" class="def record field anchored"><a href="#type-t.diff" class="anchor"></a><code><span>diff : <span><a href="#type-diff">diff</a> <span class="xref-unresolved">Base</span>.option</span>;</span></code></li><li id="type-t.id" class="def record field anchored"><a href="#type-t.id" class="anchor"></a><code><span>id : <span class="xref-unresolved">Base</span>.int;</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>Same as <code>value.id</code>.</p><span class="comment-delim">*)</span></div></li><li id="type-t.value" class="def record field anchored"><a href="#type-t.value" class="anchor"></a><code><span>value : <a href="#type-tn">tn</a>;</span></code></li><li id="type-t.top_down_prec" class="def record field anchored"><a href="#type-t.top_down_prec" class="anchor"></a><code><span>top_down_prec : <span class="xref-unresolved">Base</span>.bool;</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>Whether to propagate precision bottom-up (the default) or top-down.</p><span class="comment-delim">*)</span></div></li><li id="type-t.shape" class="def record field anchored"><a href="#type-t.shape" class="anchor"></a><code><span>shape : <a href="../Shape/index.html#type-t">Shape.t</a>;</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>The eventual shape of <code>t.value</code> and <code>t.diff.grad</code>, incorporating the current state of shape inference.</p><span class="comment-delim">*)</span></div></li><li id="type-t.children" class="def record field anchored"><a href="#type-t.children" class="anchor"></a><code><span>children : <span><a href="#type-subtensor">subtensor</a> <span class="xref-unresolved">Base</span>.list</span>;</span></code></li></ol><code><span>}</span></code></div><div class="spec-doc"><p>Information needed for compositional code generation.</p></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-subtensor"><a href="#type-subtensor" class="anchor"></a><code><span><span class="keyword">and</span> subtensor</span><span> = </span><span>{</span></code><ol><li id="type-subtensor.subtensor" class="def record field anchored"><a href="#type-subtensor.subtensor" class="anchor"></a><code><span>subtensor : <a href="#type-t">t</a>;</span></code></li><li id="type-subtensor.embedded" class="def record field anchored"><a href="#type-subtensor.embedded" class="anchor"></a><code><span>embedded : <span class="xref-unresolved">Base</span>.bool;</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>A tensor can be an <code>embedded</code> child at most once -- that's where its <code>forward</code> computation ends up when used as part of a bigger computation.</p><span class="comment-delim">*)</span></div></li></ol><code><span>}</span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-comparator_witness"><a href="#type-comparator_witness" class="anchor"></a><code><span><span class="keyword">and</span> comparator_witness</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-sexp_of_t"><a href="#val-sexp_of_t" class="anchor"></a><code><span><span class="keyword">val</span> sexp_of_t : <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Sexplib0</span>.Sexp.t</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-sexp_of_subtensor"><a href="#val-sexp_of_subtensor" class="anchor"></a><code><span><span class="keyword">val</span> sexp_of_subtensor : <span><a href="#type-subtensor">subtensor</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Sexplib0</span>.Sexp.t</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-sexp_of_comparator_witness"><a href="#val-sexp_of_comparator_witness" class="anchor"></a><code><span><span class="keyword">val</span> sexp_of_comparator_witness : <span><a href="#type-comparator_witness">comparator_witness</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Sexplib0</span>.Sexp.t</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-comparator"><a href="#val-comparator" class="anchor"></a><code><span><span class="keyword">val</span> comparator : <span><span>(<a href="#type-t">t</a>, <a href="#type-comparator_witness">comparator_witness</a>)</span> <span class="xref-unresolved">Base</span>.Comparator.t</span></span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-init_params"><a href="#val-init_params" class="anchor"></a><code><span><span class="keyword">val</span> init_params : <span><span class="optlabel">?skip</span>:<span><span class="type-var">'a</span> <span class="xref-unresolved">Base</span>.Map.M(<span class="xref-unresolved">Ir</span>.Tnode).t</span> <span class="arrow">&#45;&gt;</span></span> <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <a href="#type-comp">comp</a></span></code></div><div class="spec-doc"><p><code>init_params ?skip t</code> collects into a single sequence the <a href="#type-t.forward"><code>forward</code></a> code of <code>t.params</code>, and transitively the initializations of the parameters of the parameters. If <code>skip</code> is provided, it is used to filter out the parameters belonging to <code>skip</code> (e.g. <code>skip</code> can be a set of parameters that are already initialized). NOTE: it always outputs code with a block comment, even if the params set is empty.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-is_fwd_root"><a href="#val-is_fwd_root" class="anchor"></a><code><span><span class="keyword">val</span> is_fwd_root : <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.bool</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-remove_fwd_root"><a href="#val-remove_fwd_root" class="anchor"></a><code><span><span class="keyword">val</span> remove_fwd_root : <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.unit</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-is_bprop_root"><a href="#val-is_bprop_root" class="anchor"></a><code><span><span class="keyword">val</span> is_bprop_root : <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.bool</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-remove_bprop_root"><a href="#val-remove_bprop_root" class="anchor"></a><code><span><span class="keyword">val</span> remove_bprop_root : <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.unit</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-with_unchanged_roots"><a href="#val-with_unchanged_roots" class="anchor"></a><code><span><span class="keyword">val</span> with_unchanged_roots : <span><span class="label">f</span>:<span>(<span><span class="xref-unresolved">Base</span>.unit <span class="arrow">&#45;&gt;</span></span> <span class="type-var">'a</span>)</span> <span class="arrow">&#45;&gt;</span></span> <span class="type-var">'a</span></span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-default_value_prec"><a href="#val-default_value_prec" class="anchor"></a><code><span><span class="keyword">val</span> default_value_prec : <span><a href="../../../arrayjit/Ir/Ops/index.html#type-prec">Ir.Ops.prec</a> <span class="xref-unresolved">Base</span>.ref</span></span></code></div><div class="spec-doc"><p>The default precision for the value node of terminal (i.e. non-composite) tensors.</p><p>Note: the precision of a node can be set arbitrarily via <a href="../../../arrayjit/Ir/Tnode/index.html#val-update_prec"><code>Ir.Tnode.update_prec</code></a>. The default precision for value nodes of composite tensors is the maximum of precisions of the value nodes of sub-tensors.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-default_grad_prec"><a href="#val-default_grad_prec" class="anchor"></a><code><span><span class="keyword">val</span> default_grad_prec : <span><a href="../../../arrayjit/Ir/Ops/index.html#type-prec">Ir.Ops.prec</a> <span class="xref-unresolved">Base</span>.ref</span></span></code></div><div class="spec-doc"><p>The default precision for the gradient node of terminal (i.e. non-composite) tensors.</p><p>Note: the precision of a node can be set arbitrarily via <a href="../../../arrayjit/Ir/Tnode/index.html#val-update_prec"><code>Ir.Tnode.update_prec</code></a>. The default precision for gradient nodes of composite tensors is the maximum of precisions of the gradient nodes of sub-tensors.</p></div></div><div class="odoc-spec"><div class="spec exception anchored" id="exception-Session_error"><a href="#exception-Session_error" class="anchor"></a><code><span><span class="keyword">exception</span> </span><span><span class="exception">Session_error</span> <span class="keyword">of</span> <span class="xref-unresolved">Base</span>.string * <span><a href="#type-t">t</a> <span class="xref-unresolved">Base</span>.option</span></span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-max_sublabel_length"><a href="#val-max_sublabel_length" class="anchor"></a><code><span><span class="keyword">val</span> max_sublabel_length : <span><span class="xref-unresolved">Base</span>.int <span class="xref-unresolved">Base</span>.ref</span></span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-raw_ternop"><a href="#val-raw_ternop" class="anchor"></a><code><span><span class="keyword">val</span> raw_ternop : 
  <span><span class="label">initialize_neutral</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">accum</span>:<a href="../../../arrayjit/Ir/Ops/index.html#type-binop">Ir.Ops.binop</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">t</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">lhs_is_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">op</span>:<a href="../../../arrayjit/Ir/Ops/index.html#type-ternop">Ir.Ops.ternop</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">t1</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs1_is_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs1_is_merge</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">t2</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs2_is_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs2_is_merge</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">t3</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs3_is_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs3_is_merge</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">logic</span>:<a href="../Shape/index.html#type-ternary_type">Shape.ternary_type</a> <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-asgns">asgns</a></span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-raw_binop"><a href="#val-raw_binop" class="anchor"></a><code><span><span class="keyword">val</span> raw_binop : 
  <span><span class="label">initialize_neutral</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">accum</span>:<a href="../../../arrayjit/Ir/Ops/index.html#type-binop">Ir.Ops.binop</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">t</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">lhs_is_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">op</span>:<a href="../../../arrayjit/Ir/Ops/index.html#type-binop">Ir.Ops.binop</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">t1</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs1_is_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs1_is_merge</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">t2</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs2_is_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs2_is_merge</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">logic</span>:<a href="../Shape/index.html#type-compose_type">Shape.compose_type</a> <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-asgns">asgns</a></span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-raw_unop"><a href="#val-raw_unop" class="anchor"></a><code><span><span class="keyword">val</span> raw_unop : 
  <span><span class="label">initialize_neutral</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">accum</span>:<a href="../../../arrayjit/Ir/Ops/index.html#type-binop">Ir.Ops.binop</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">t</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">lhs_is_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">op</span>:<a href="../../../arrayjit/Ir/Ops/index.html#type-unop">Ir.Ops.unop</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">t1</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs_is_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">rhs_is_merge</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">logic</span>:<a href="../Shape/index.html#type-transpose_type">Shape.transpose_type</a> <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-asgns">asgns</a></span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-grad_spec"><a href="#type-grad_spec" class="anchor"></a><code><span><span class="keyword">type</span> grad_spec</span><span> = </span></code><ol><li id="type-grad_spec.Require_grad" class="def variant constructor anchored"><a href="#type-grad_spec.Require_grad" class="anchor"></a><code><span>| </span><span><span class="constructor">Require_grad</span></span></code></li><li id="type-grad_spec.Prohibit_grad" class="def variant constructor anchored"><a href="#type-grad_spec.Prohibit_grad" class="anchor"></a><code><span>| </span><span><span class="constructor">Prohibit_grad</span></span></code></li><li id="type-grad_spec.If_needed" class="def variant constructor anchored"><a href="#type-grad_spec.If_needed" class="anchor"></a><code><span>| </span><span><span class="constructor">If_needed</span></span></code></li></ol></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-is_prohibit_grad"><a href="#val-is_prohibit_grad" class="anchor"></a><code><span><span class="keyword">val</span> is_prohibit_grad : <span><a href="#type-grad_spec">grad_spec</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.bool</span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-param_op_fun"><a href="#type-param_op_fun" class="anchor"></a><code><span><span class="keyword">type</span> param_op_fun</span><span> =
  <span><span class="optlabel">?input_dims</span>:<span><span class="xref-unresolved">Base</span>.int <span class="xref-unresolved">Base</span>.list</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?output_dims</span>:<span><span class="xref-unresolved">Base</span>.int <span class="xref-unresolved">Base</span>.list</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?input_axes</span>:<span><span>(<span class="xref-unresolved">Base</span>.string * <span class="xref-unresolved">Base</span>.int)</span> <span class="xref-unresolved">Base</span>.list</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?output_axes</span>:<span><span>(<span class="xref-unresolved">Base</span>.string * <span class="xref-unresolved">Base</span>.int)</span> <span class="xref-unresolved">Base</span>.list</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?deduced</span>:<a href="../Shape/index.html#type-deduce_within_shape">Shape.deduce_within_shape</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="xref-unresolved">Base</span>.unit <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-t">t</a></span></code></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-op_fun"><a href="#type-op_fun" class="anchor"></a><code><span><span class="keyword">type</span> op_fun</span><span> =
  <span><span class="optlabel">?label</span>:<span><span class="xref-unresolved">Base</span>.string <span class="xref-unresolved">Base</span>.list</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?top_down_prec</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?batch_dims</span>:<span><span class="xref-unresolved">Base</span>.int <span class="xref-unresolved">Base</span>.list</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?batch_axes</span>:<span><span>(<span class="xref-unresolved">Base</span>.string * <span class="xref-unresolved">Base</span>.int)</span> <span class="xref-unresolved">Base</span>.list</span> <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-param_op_fun">param_op_fun</a></span></code></div><div class="spec-doc"><p>Labels are collected in tensor construction order, with more specific information first.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-binop"><a href="#val-binop" class="anchor"></a><code><span><span class="keyword">val</span> binop : 
  <span><span class="optlabel">?compose_op</span>:<a href="../Shape/index.html#type-compose_type">Shape.compose_type</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">op_asn</span>:<span>(<span><span class="label">v</span>:<a href="#type-tn">tn</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t1</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t2</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">projections</span>:<a href="#type-projections">projections</a> <span class="arrow">&#45;&gt;</span></span> <a href="#type-comp">comp</a>)</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">grad_asn</span>:<span>(<span><span class="label">t</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">g</span>:<a href="#type-tn">tn</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t1</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t2</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">projections</span>:<a href="#type-projections">projections</a> <span class="arrow">&#45;&gt;</span></span> <a href="#type-comp">comp</a>)</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?grad_spec</span>:<a href="#type-grad_spec">grad_spec</a> <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-op_fun">op_fun</a></span></code></div><div class="spec-doc"><p>The defaults are pointwise operations. The <code>grad_asn</code> function receives the non-differentiable variant of the tensor as an argument, which can be used to access the tensor's value in a tensor expression.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-unop"><a href="#val-unop" class="anchor"></a><code><span><span class="keyword">val</span> unop : 
  <span><span class="optlabel">?transpose_op</span>:<a href="../Shape/index.html#type-transpose_type">Shape.transpose_type</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">op_asn</span>:<span>(<span><span class="label">v</span>:<a href="#type-tn">tn</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t1</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">projections</span>:<a href="#type-projections">projections</a> <span class="arrow">&#45;&gt;</span></span> <a href="#type-comp">comp</a>)</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">grad_asn</span>:<span>(<span><span class="label">t</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">g</span>:<a href="#type-tn">tn</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t1</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">projections</span>:<a href="#type-projections">projections</a> <span class="arrow">&#45;&gt;</span></span> <a href="#type-comp">comp</a>)</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?grad_spec</span>:<a href="#type-grad_spec">grad_spec</a> <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-op_fun">op_fun</a></span></code></div><div class="spec-doc"><p>See <a href="#val-binop"><code>binop</code></a> -- same comments apply.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-ternop"><a href="#val-ternop" class="anchor"></a><code><span><span class="keyword">val</span> ternop : 
  <span><span class="optlabel">?ternary_op</span>:<a href="../Shape/index.html#type-ternary_type">Shape.ternary_type</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">op_asn</span>:<span>(<span><span class="label">v</span>:<a href="#type-tn">tn</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t1</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t2</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t3</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">projections</span>:<a href="#type-projections">projections</a> <span class="arrow">&#45;&gt;</span></span> <a href="#type-comp">comp</a>)</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">grad_asn</span>:
    <span>(<span><span class="label">t</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">g</span>:<a href="#type-tn">tn</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t1</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t2</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">t3</span>:<a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span><span class="label">projections</span>:<a href="#type-projections">projections</a> <span class="arrow">&#45;&gt;</span></span> <a href="#type-comp">comp</a>)</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?grad_spec</span>:<a href="#type-grad_spec">grad_spec</a> <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-op_fun">op_fun</a></span></code></div><div class="spec-doc"><p>See <a href="#val-binop"><code>binop</code></a> -- same comments apply.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-term"><a href="#val-term" class="anchor"></a><code><span><span class="keyword">val</span> term : 
  <span><span class="optlabel">?init_data</span>:<a href="../../../arrayjit/Ir/Assignments/index.html#type-init_data">Ir.Assignments.init_data</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?fetch_op</span>:<a href="#type-fetch_op">fetch_op</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?grad_spec</span>:<a href="#type-grad_spec">grad_spec</a> <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-op_fun">op_fun</a></span></code></div></div><p>A terminal: a constant, a parameter, an input of the model. The semantics of shape specification is the same as in <a href="../Shape/index.html#val-make"><code>Shape.make</code></a>, and by default the shape will be inferred. At most one of <code>init_data</code> or <code>fetch_op</code> should be provided. If <code>init_data</code> is provided, it is used to initialize the tensor's <code>value</code> node. If <code>fetch_op</code> is provided, it is used to generate the tensor's forward code. If <code>init_data</code> is provided, it is also used to verify the shape of the tensor's <code>value</code> node: <code>Reshape</code> (the default) if the data is not padded and both the tensor's shape and padding are inferred, <code>Keep_shape_no_padding</code> if the tensor should not be padded and the shape is as given by the ndarray, and <code>Padded</code> if the data is already padded as given, and the shape is as given by the ndarray.</p><div class="odoc-spec"><div class="spec value anchored" id="val-number"><a href="#val-number" class="anchor"></a><code><span><span class="keyword">val</span> number : 
  <span><span class="optlabel">?label</span>:<span><span class="xref-unresolved">Base</span>.string <span class="xref-unresolved">Base</span>.list</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?axis_label</span>:<span class="xref-unresolved">Base</span>.string <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?grad_spec</span>:<a href="#type-grad_spec">grad_spec</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="xref-unresolved">Base</span>.float <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-t">t</a></span></code></div><div class="spec-doc"><p>A number: a tensor with a single axis of one dimension, initialized to the given value. <code>grad_spec</code> is by default <code>Prohibit_grad</code>.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-bits"><a href="#val-bits" class="anchor"></a><code><span><span class="keyword">val</span> bits : 
  <span><span class="optlabel">?label</span>:<span><span class="xref-unresolved">Base</span>.string <span class="xref-unresolved">Base</span>.list</span> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?axis_label</span>:<span class="xref-unresolved">Base</span>.string <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?grad_spec</span>:<a href="#type-grad_spec">grad_spec</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="xref-unresolved">Base</span>.int64 <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-t">t</a></span></code></div><div class="spec-doc"><p>A number with exact bit representation: a tensor with a single axis of one dimension, initialized to the given int64 value. Useful for initializing uint4x32 tensors where exact bit patterns matter. <code>grad_spec</code> is by default <code>Prohibit_grad</code>.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-ndarray"><a href="#val-ndarray" class="anchor"></a><code><span><span class="keyword">val</span> ndarray : <span><span class="optlabel">?grad_spec</span>:<a href="#type-grad_spec">grad_spec</a> <span class="arrow">&#45;&gt;</span></span> <span><span><span class="xref-unresolved">Base</span>.float <span class="xref-unresolved">Base</span>.array</span> <span class="arrow">&#45;&gt;</span></span> <a href="#type-op_fun">op_fun</a></span></code></div><div class="spec-doc"><p>A tensor with an explicit shape, initialized to the given values. Omitted shape rows default to no axes. <code>grad_spec</code> is by default <code>Prohibit_grad</code>. If <code>strict</code> is <code>true</code> (the default), the given values must fill the tensor's <code>value</code> node precisely; otherwise, the values will be looped over to populate the <code>value</code> node.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-param"><a href="#val-param" class="anchor"></a><code><span><span class="keyword">val</span> param : 
  <span><span class="label">t</span>:<a href="#type-op_fun">op_fun</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="xref-unresolved">Base</span>.string <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?more_label</span>:<span><span class="xref-unresolved">Base</span>.string <span class="xref-unresolved">Base</span>.list</span> <span class="arrow">&#45;&gt;</span></span>
  <a href="#type-param_op_fun">param_op_fun</a></span></code></div><div class="spec-doc"><p>For proper parameters, <code>t</code> should produce a tensor with no batch axes; input and output axes should by default be inferred; <code>grad_spec</code> should be <code>Require_grad</code>. <code>t</code>'s label is the passed string, appended by <code>more_label</code> if any, other parameters are forwarded to <code>t</code>. This function returns <code>t</code>'s result with the field <a href="#type-t.params"><code>params</code></a> replaced by a singleton set containing that result, and it also updates the memory modes.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-term_init"><a href="#val-term_init" class="anchor"></a><code><span><span class="keyword">val</span> term_init : <span><span class="optlabel">?grad_spec</span>:<a href="#type-grad_spec">grad_spec</a> <span class="arrow">&#45;&gt;</span></span> <span><span><span class="xref-unresolved">Base</span>.float <span class="xref-unresolved">Base</span>.array</span> <span class="arrow">&#45;&gt;</span></span> <a href="#type-op_fun">op_fun</a></span></code></div><div class="spec-doc"><p>A <a href="#val-term"><code>term</code></a> wrapper that sets up the value node initialization (it generalizes <a href="#val-ndarray"><code>ndarray</code></a> to tensors with inferred shapes).</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-consume_forward_code"><a href="#val-consume_forward_code" class="anchor"></a><code><span><span class="keyword">val</span> consume_forward_code : <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <a href="#type-comp">comp</a></span></code></div><div class="spec-doc"><p>A forward root is a tensor that is not (currently) used to compute another tensor. <code>consume_forward_code t</code> ensures <code>t</code> is a forward root, removes it from forward roots, and checks that there are no other forward roots for tensors with children.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-consume_backprop_code"><a href="#val-consume_backprop_code" class="anchor"></a><code><span><span class="keyword">val</span> consume_backprop_code : <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <a href="#type-comp">comp</a></span></code></div><div class="spec-doc"><p>A backprop root is a tensor with a gradient that is not (currently) receiving gradients from another tensor. I.e. it is not currently used to compute a tensor with a gradient. <code>consume_backprop_code t</code> ensures <code>t</code> is a backprop root, removes it from backprop roots, and checks that there are no other backprop roots for tensors with children. It returns the backprop code -- note this does not include the zero_grads code.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-iter_embedded"><a href="#val-iter_embedded" class="anchor"></a><code><span><span class="keyword">val</span> iter_embedded : <span><span class="label">f</span>:<span>(<span><a href="#type-tn">tn</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.unit)</span> <span class="arrow">&#45;&gt;</span></span> <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.unit</span></code></div><div class="spec-doc"><p><code>iter_embedded t</code> iterates over all descendant nodes that are embedded, i.e. are members of <code>t.forward.embedded_nodes</code> or '<code>t.diff.backprop.embedded_nodes</code>' (if any). Note: <code>iter_embedded</code> should only be called after shape inference finishes.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-unsafe_reinitialize"><a href="#val-unsafe_reinitialize" class="anchor"></a><code><span><span class="keyword">val</span> unsafe_reinitialize : <span><span class="xref-unresolved">Base</span>.unit <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.unit</span></code></div><div class="spec-doc"><p>Bring global state to its initialization values. This invalidates any previously defined tensors and tensor nodes. Also reinitializes the modules: <a href="../Shape/index.html"><code>Shape</code></a>, <a href="../../../arrayjit/Ir/Tnode/index.html"><code>Ir.Tnode</code></a>.</p><p>While this function is intended for testing, using it can prevent unintentional session state pollution errors.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-set_random_seed"><a href="#val-set_random_seed" class="anchor"></a><code><span><span class="keyword">val</span> set_random_seed : <span><span class="optlabel">?seed</span>:<span class="xref-unresolved">Base</span>.int <span class="arrow">&#45;&gt;</span></span> <span><span class="xref-unresolved">Base</span>.unit <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.unit</span></code></div><div class="spec-doc"><p>Creates the random seed tensor. If <code>seed</code> is provided, it is used to set the random seed. Otherwise, the seed is taken from the settings.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-get_random_seed"><a href="#val-get_random_seed" class="anchor"></a><code><span><span class="keyword">val</span> get_random_seed : <span><span class="xref-unresolved">Base</span>.unit <span class="arrow">&#45;&gt;</span></span> <a href="#type-t">t</a></span></code></div><div class="spec-doc"><p>Returns a tensor with the current random seed. Lazily initialized using <a href="#val-set_random_seed"><code>set_random_seed</code></a> and reset when <a href="#val-unsafe_reinitialize"><code>unsafe_reinitialize</code></a> is called. IMPORTANT: all sites using the same global random seed, e.g. using <code>get_random_seed ()</code> not separated by a call to <a href="#val-unsafe_reinitialize"><code>unsafe_reinitialize</code></a>, must descend from the first caller's optimization context.</p></div></div><h3 id="printing."><a href="#printing." class="anchor"></a>Printing.</h3><div class="odoc-spec"><div class="spec value anchored" id="val-header"><a href="#val-header" class="anchor"></a><code><span><span class="keyword">val</span> header : <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.string</span></code></div><div class="spec-doc"><p>Converts ID, label and the dimensions of a node to a string.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-log_debug_info"><a href="#val-log_debug_info" class="anchor"></a><code><span><span class="keyword">val</span> log_debug_info : <span><span class="label">from_log_level</span>:<span class="xref-unresolved">Base</span>.int <span class="arrow">&#45;&gt;</span></span> <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.unit</span></code></div><div class="spec-doc"><p>Logs debug information about the tensor on the default ppx_minidebug runtime.</p></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-array_print_style"><a href="#type-array_print_style" class="anchor"></a><code><span><span class="keyword">type</span> array_print_style</span><span> = </span><span>[ </span></code><ol><li id="type-array_print_style.Default" class="def variant constructor anchored"><a href="#type-array_print_style.Default" class="anchor"></a><code><span>| </span><span>`Default</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>The inner rectangles comprise both an input and an output axis, if available. Similarly, the outer rectangle comprises a second-from-end input axis and a second-from-end output axis, if available. At least one batch axis is output, when available. The axes that couldn't be output are printed at position/dimension <code>0</code>.</p><span class="comment-delim">*)</span></div></li><li id="type-array_print_style.N5_layout" class="def variant constructor anchored"><a href="#type-array_print_style.N5_layout" class="anchor"></a><code><span>| </span><span>`N5_layout <span class="keyword">of</span> <span class="xref-unresolved">Base</span>.string</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>The string should provide exclusively non-negative integer pseudo-labels. The numbers <code>0</code>-<code>4</code> represent the priorities of the axes to be printed out, where the priorities correspond to, from highest: horizontal, vertical direction of the inner rectangle, horizontal, vertical direction of the outer rectangle, repetition (see also <code>Node.pp_print</code>). The numbers <code>n &gt;= 5</code> stand for the actual positions <code>n - 5</code> within the corresponding axes.</p><span class="comment-delim">*)</span></div></li><li id="type-array_print_style.Label_layout" class="def variant constructor anchored"><a href="#type-array_print_style.Label_layout" class="anchor"></a><code><span>| </span><span>`Label_layout <span class="keyword">of</span> <span><span>(<span class="xref-unresolved">Base</span>.string * <span class="xref-unresolved">Base</span>.int)</span> <span class="xref-unresolved">Base</span>.list</span></span></code><div class="def-doc"><span class="comment-delim">(*</span><p>The association from axis labels to integers. The negative numbers <code>-5</code> to <code>-1</code> represent the priorities of the axes to be printed out, where the priorities correspond to, from highest: horizontal, vertical direction of the inner rectangle, horizontal, vertical direction of the outer rectangle, repetition (as above). The numbers <code>n &gt;= 0</code> stand for the actual positions within the corresponding axes. Unspecified axes are printed at position <code>0</code>.</p><span class="comment-delim">*)</span></div></li><li id="type-array_print_style.Inline" class="def variant constructor anchored"><a href="#type-array_print_style.Inline" class="anchor"></a><code><span>| </span><span>`Inline</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>The tensors are printed linearly, in a bracketed manner, optionally prefixed with the labels specification. Note that the syntax causes ambiguity for 1-dimensional input axes (underscores are used for axes without explicit labels); when there is a 1-dimensional input axis, we output the labels specification even if there are no axis labels as a way to display the number of axes. The axis nesting is right-to-left (rightmost is innermost). The input axes are innermost and the batch axes outermost. The input axes use <code>,</code> as a separator and <code>()</code> as axis delimiters, but the delimiter for the outermost (i.e. leftmost) axis is omitted. The output axes use <code>;</code> as a separator and <code>[]</code> as axis delimiters (obligatory). The batch axes use <code>;</code> as a separator and <code>[||]</code> as axis delimiters (obligatory).</p><span class="comment-delim">*)</span></div></li></ol><code><span> ]</span></code></div><div class="spec-doc"><p>We print out up to 5 axes when printing a tensor, as a grid (outer rectangle) of (inner) rectangles, possibly repeated (screens).</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-to_printbox"><a href="#val-to_printbox" class="anchor"></a><code><span><span class="keyword">val</span> to_printbox : 
  <span><span class="optlabel">?single_node</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?embedded_only</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?entries_per_axis</span>:<span class="xref-unresolved">Base</span>.int <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?with_id</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?force</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?with_shape</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?with_value</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">with_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">depth</span>:<span class="xref-unresolved">Base</span>.int <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span class="xref-unresolved">PrintBox</span>.t</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-to_doc"><a href="#val-to_doc" class="anchor"></a><code><span><span class="keyword">val</span> to_doc : 
  <span><span class="label">force</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">with_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">with_code</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?with_low_level</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-array_print_style">array_print_style</a> <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span class="xref-unresolved">PPrint</span>.document</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-print"><a href="#val-print" class="anchor"></a><code><span><span class="keyword">val</span> print : 
  <span><span class="optlabel">?here</span>:<span class="xref-unresolved">Ppx_here_lib</span>.position <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?force</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">with_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">with_code</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?with_low_level</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-array_print_style">array_print_style</a> <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span class="xref-unresolved">Base</span>.unit</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-print_forward_roots"><a href="#val-print_forward_roots" class="anchor"></a><code><span><span class="keyword">val</span> print_forward_roots : 
  <span><span class="label">with_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">with_code</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-array_print_style">array_print_style</a> <span class="arrow">&#45;&gt;</span></span>
  <span class="xref-unresolved">Base</span>.unit</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-print_tree"><a href="#val-print_tree" class="anchor"></a><code><span><span class="keyword">val</span> print_tree : 
  <span><span class="optlabel">?here</span>:<span class="xref-unresolved">Ppx_here_lib</span>.position <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?force</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?entries_per_axis</span>:<span class="xref-unresolved">Base</span>.int <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?with_backend_info</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?with_id</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?with_shape</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?with_value</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?embedded_only</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">with_grad</span>:<span class="xref-unresolved">Base</span>.bool <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">depth</span>:<span class="xref-unresolved">Base</span>.int <span class="arrow">&#45;&gt;</span></span>
  <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span>
  <span class="xref-unresolved">Base</span>.unit</span></code></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-debug_name"><a href="#val-debug_name" class="anchor"></a><code><span><span class="keyword">val</span> debug_name : <span><a href="#type-t">t</a> <span class="arrow">&#45;&gt;</span></span> <span class="xref-unresolved">Base</span>.string</span></code></div></div></div></body></html>
