Specification of a terminal [Formula.t]'s shape. The [string] occurrences refer to [axis_labels]
    specs. Note: the specification is just a helper in constructing shapes.
{[type term_spec =
  | Unknown_shape
  (** The shape will need to be fully inferred. *)
  | Constant of {output_dims: int list; axis_labels: string}
  (** Shape of a constant has no batch nor input dimensions, only output dimensions. *)
  | Data of {batch_dims: int list; output_dims: int list; axis_labels: string}
  (** A data shape does not have input dimensions. *)
  | Params of {input_dims: int list; output_dims: int list; axis_labels: string}
  (** A parameters shape with fixed dimensionality. Parameters do not have batch dimensions. *)
  | Given_output_params of {input_dims: int list; output_dims: int list; axis_labels: string}
  (** A parameters shape with fixed output dimensionality, but input shape still gets inferred.
      Parameters do not have batch dimensions. *)
  | Transform of {batch_dims: int list; input_dims: int list; output_dims: int list; axis_labels: string}
  (** A non-differentiable transformation(s) shape. *)
  | Unknown_batch_data of {output_dims: int list; axis_labels: string}
  (** A data shape where the batch dimensions are left up to inference. *)
  | Deduced_params of deduce_dims
    (** Parameters with inferred dimensionality. Use cases:
        [Deduced_params Not_constrained] -- the shape will need to be fully inferred (no batch dims).
        [Deduced_params Input_equals_output] -- a hidden layer preserving the dimensionality.
        [Deduced_params (Input_output_scale 2.0)] -- an expansion hidden layer doubling the dimensionality.
        [Deduced_params (Input_output_scale 0.5)] -- an bottleneck hidden layer halving the dimensionality.
        Note that scalar axes (1D) are not scaled, for compatibility with broadcasting. *)

let of_term_spec id: term_spec -> t = function
  | Unknown_shape ->
    { batch=Unknown; input=Unknown; output=Unknown;
      axis_labels=Map.empty (module AxisKey);
      deduce_within_shape_constraints=Not_constrained; id }
  | Constant {output_dims; axis_labels} ->
    { batch=Given []; input=Given []; output=Given output_dims;
      axis_labels=(axis_labels_of_spec axis_labels).labels;
      deduce_within_shape_constraints=Not_constrained; id }
  | Data {batch_dims; output_dims; axis_labels} ->
    { batch=Given batch_dims; input=Given []; output=Given output_dims;
      axis_labels=(axis_labels_of_spec axis_labels).labels;
      deduce_within_shape_constraints=Not_constrained; id }
  | Params {input_dims; output_dims; axis_labels} ->
    { batch=Given []; input=Given input_dims; output=Given output_dims;
      axis_labels=(axis_labels_of_spec axis_labels).labels;
      deduce_within_shape_constraints=Not_constrained; id }
  | Transform {batch_dims; input_dims; output_dims; axis_labels} ->
    { batch=Given batch_dims; input=Given input_dims; output=Given output_dims;
      axis_labels=(axis_labels_of_spec axis_labels).labels;
      deduce_within_shape_constraints=Not_constrained; id }
  | Unknown_batch_data {output_dims; axis_labels} ->
    { batch=Unknown; input=Given []; output=Given output_dims;
      axis_labels=(axis_labels_of_spec axis_labels).labels;
      deduce_within_shape_constraints=Not_constrained; id }
  | Deduced_params deduce_within_shape_constraints ->
    { batch=Given []; input=Unknown; output=Unknown;
      axis_labels=Map.empty (module AxisKey);
      deduce_within_shape_constraints; id }

let term_needs_gradient spec =
  match spec with
  | Unknown_shape -> true
  | Data _ -> false
  | Constant _ -> false
  | Params _ -> true
  | Given_output_arams _ -> true
  | Transform _ -> false
  | Unknown_batch_data _ -> false
  | Deduced_params _ -> true


    | LLCreate { tensor=Value_at_node_id id; dims; init_op } ->
      fprintf ppf "@[<2>(get %d).value <-@ create_ndarray Single@ %a %a@]" id pp_dims dims pp_print_init_op init_op
    | LLCreate { tensor=Gradient_at_node_id id; dims; init_op } ->
      fprintf ppf "@[<2>(get_form %d).grad <-@ create_ndarray Single@ %a %a@]" id pp_dims dims pp_print_init_op init_op


  let pp_dims ppf dims =
    fprintf ppf "[|%a|]" (pp_print_list ~pp_sep:pp_semi pp_print_int) @@ Array.to_list dims in

  | LLFetch: {
      tensor: data low_level; fetch_op: fetch_op;
    } -> unit low_level

    | LLFetch { tensor=Value_at_node_id id; fetch_op } ->
      fetch_ndarray fetch_op ((get id).value)
    | LLFetch { tensor=Gradient_at_node_id id; fetch_op } ->
      fetch_ndarray fetch_op ((get_form id).grad)

    | LLFetch { tensor=Value_at_node_id id; fetch_op } ->
      fprintf ppf "@[<2>fetch_ndarray_callback@ ~op_or_id:%a@ ((get %d).value)@]"
        (pp_print_fetch_op ~id) fetch_op id
    | LLFetch { tensor=Gradient_at_node_id id; fetch_op } ->
      fprintf ppf "@[<2>fetch_ndarray_callback@ ~op_or_id:%a@ ((get_form %d).grad)@]"
        (pp_print_fetch_op ~id) fetch_op id



  | Range_over_axis_from_end of int
  (** Fills in the index number of the specified axis counting from end.
      [Range_over_axis_from_end 1] is the range over the last axis. *)

  | Range_over_axis_from_end d ->
    Caml.Format.(fprintf ppf "(Range_over_axis_from_end %d)" d)

  | Range_over_axis_from_end d ->
    init_array_of_prec prec dims ~f:(fun idcs -> Float.of_int @@ idcs.(Array.length idcs - d))

  | Init_op (Range_over_axis_from_end d) ->
    loop_bigarray arr ~f:(fun idcs -> cast @@ Float.of_int @@ idcs.(Array.length idcs - d))


  | Standard_gaussian
  (** Draws the values from N(0,1). *)


let fetch_bigarray (fetch_op: fetch_op) (type val_t b) (cast: float -> val_t)
    (_prec: (val_t, (val_t, b, Bigarray.c_layout) bigarray) precision)
    (arr: (val_t, b, Bigarray.c_layout) bigarray) =
  let dims = A.dims arr in
  match fetch_op with
  | Init_op (Unspecified) ->
    ()
  | Init_op (Constant_stream cs) ->
    let size = Array.length cs in
    let group_offset =
      Int.((global.session_step * Array.fold dims ~init:1 ~f:( * )) % size) in
    loop_bigarray arr
      ~f:(fun idcs -> cast cs.((indices_to_offset ~dims ~idcs + group_offset) % size))
  | Init_op (Range_over_offsets) ->
    loop_bigarray arr 
      ~f:(fun idcs -> cast @@ Float.of_int @@ indices_to_offset ~dims ~idcs)
  | Init_op (Standard_uniform) ->
    loop_bigarray arr ~f:(fun _ -> cast @@ Random.float_range 0.0 1.0)
  | Compute_point f ->
    loop_bigarray arr ~f:(fun idcs -> cast (f ~session_step:global.session_step ~dims ~idcs))

let fetch_ndarray fetch_op arr =
  let ff arr = fetch_bigarray fetch_op arr in
   cast_map_as_bigarray {ff} arr

let fetch_ndarray_callback ~op_or_id arr =
  let fetch_op =
    Either.value_map op_or_id ~first:Fn.id
      ~second:(Hashtbl.find_exn global.node_fetch_callbacks) in
  fetch_ndarray fetch_op arr


let init_ndarray_callback ~op_or_id arr =
  let init_op =
    Either.value_map op_or_id ~first:Fn.id
      ~second:(Hashtbl.find_exn global.node_init_callbacks) in
  init_ndarray init_op arr

let pp_print_fetch_op ~id ppf: Code.fetch_op -> unit = function
  | Init_op init_op ->
    Caml.Format.(fprintf ppf "(Either.First (Init_op @[<2>(%a)@]))" pp_print_init_op init_op)
  | (Compute_point _) as callback ->
    let open Ocannl_runtime in
    Hashtbl.update Node.global.node_fetch_callbacks id ~f:(function
        | None -> callback
        | Some other ->
          (if not @@ phys_equal other callback then invalid_arg
               "exec_as_OCaml: multiple fetch callbacks for the same node not supported currently");
          callback
    );
    Caml.Format.(fprintf ppf "(Either.Second %d)" id)

  let point_input = FDSL.data ~label:"point_input" ~batch_dims:[1] ~output_dims:[2]
      (Compute_point (fun ~session_step:_ ~dims:_ ~idcs -> point.(idcs.(1)))) in

    let size = Array.length cs in
    let group_offset =
      Int.((global.session_step * Array.fold dims ~init:1 ~f:( * )) % size) in
    loop_bigarray arr
      ~f:(fun idcs -> cast cs.((indices_to_offset ~dims ~idcs + group_offset) % size))

]}